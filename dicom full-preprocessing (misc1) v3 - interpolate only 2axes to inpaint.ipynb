{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification\n",
    "\n",
    "**dicom full-preprocessing (misc1) v3 - interpolate only 2axes to inpaint**\n",
    "1. We resample along the vertical and horizontal axes but we don't resample along the slices. This creates a smaller volume to apply inpainting. The slices axis has to be resamples later\n",
    "1. We dilate the union of the segmentations\n",
    "1. We dilate the lungs mask with kernel=1 (it was 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared to the previous version (v2), this script removes the scans with bad\n",
    "# slices (>2.5mm or inconsistency between spacing and thickness)\n",
    "\n",
    "import os # module for interfacing with the os\n",
    "import numpy as np # numpy for arrays etc\n",
    "import pandas as pd # module for creating and querying data tables (databases) efficiently\n",
    "import pylidc as pl # module for handling the LIDC dataset\n",
    "import matplotlib.pyplot as plt # plotting utilities\n",
    "import scipy.ndimage # \n",
    "import scipy.sparse\n",
    "import scipy\n",
    "from preprocessing.preprocess_functions import *\n",
    "from utils_LIDC.utils_LIDC import *\n",
    "from pylidc.utils import consensus\n",
    "from skimage.morphology import ball, dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIDC_PATH = '/data/datasets/LIDC-IDRI/' # original LIDC data\n",
    "# annotations = pd.read_csv('/data/datasets/LIDC-IDRI/annotations.csv')\n",
    "LIDC_IDs = os.listdir(f'{LIDC_PATH}LIDC-IDRI')\n",
    "LIDC_IDs = [i for i in LIDC_IDs if 'LIDC' in i]\n",
    "LIDC_IDs = np.sort(LIDC_IDs)\n",
    "\n",
    "# output path\n",
    "path_dest = f'/data/OMM/Datasets/LIDC_other_formats/LIDC_preprocessed_3D v4 - inpaint before preprocess/' \n",
    "if not os.path.exists(path_dest): os.makedirs(path_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all the scans for X patient(s)\n",
    "df = pd.read_csv('/data/datasets/LIDC-IDRI/annotations.csv')\n",
    "\n",
    "#%%\n",
    "scans_with_errors = []\n",
    "errorScansFile = open(path_dest + \"scans_with_errors.txt\",\"w\")\n",
    "\n",
    "numVoxelsPerLungSeg = []\n",
    "listOfRejectedPatients = []\n",
    "rejectListFile = open(path_dest + \"rejectedPatients.txt\",\"w\") \n",
    "\n",
    "listOfUsedPatients = []\n",
    "useListFile = open(path_dest + \"usedPatients.txt\",\"w\") \n",
    "\n",
    "requiredSelemWidth = []\n",
    "selemZWidthFile = open(path_dest + \"segmentationSelemZWidths.txt\",\"w\") \n",
    "\n",
    "for idx, k in enumerate(LIDC_IDs):\n",
    "    # SCAN idx==41, 61 has an error\n",
    "    if idx<=782:continue\n",
    "#     if idx <=10:continue\n",
    "#     if idx ==300:break\n",
    "\n",
    "    k = LIDC_IDs[idx]\n",
    "\n",
    "    #if idx>5:break\n",
    "    print(f'preprocessing: {idx}, {k}')\n",
    "       \n",
    "    df_patient = df.loc[df['patientid']==int(k[-4:])] \n",
    "    pid = k\n",
    "    \n",
    "    # query the LIDC images with patient_id = pid \n",
    "    # HERE WE JUST USE THE FIRST ONE!!\n",
    "    idx_scan = 0 \n",
    "    \n",
    "    # get the scan object for this scan\n",
    "    scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == pid)[idx_scan] \n",
    "    \n",
    "    # here we can reject according to any criteria we like\n",
    "    thickSlice = (scan.slice_thickness > 3) | (scan.slice_spacing > 3)\n",
    "    missingSlices = len(np.unique(np.round(100*np.diff(scan.slice_zvals)))) != 1\n",
    "    if (thickSlice)  :\n",
    "        # we want to reject this scan/patient\n",
    "        print('Undesirable slice characteristics, rejecting')\n",
    "        listOfRejectedPatients.append(pid)\n",
    "        continue\n",
    "    elif (missingSlices):\n",
    "        print('Missing slices, rejecting')\n",
    "        listOfRejectedPatients.append(pid)\n",
    "        continue\n",
    "    else:\n",
    "        # we will use this scan\n",
    "        listOfUsedPatients.append(pid)\n",
    "        #continue # this lets us quickly check the outcome of the selection\n",
    "    \n",
    "    print('Loading and converting to HU')\n",
    "    curr_patient_pixels, spacing_orig = custom_load_scan_to_HU(scan)\n",
    "\n",
    "    print('Resampling to isotropic resolution')\n",
    "    pix_resampled, spacing = resample_grid_except_slices(curr_patient_pixels, spacing_orig, [1,1,1])\n",
    "    \n",
    "    print('Segmenting the lungs and dilating the mask')\n",
    "    try:\n",
    "        segmented_lungs_fill, requiredSelemWidthTmp = segment_lung_mask(pix_resampled, True)\n",
    "    except IndexError: continue\n",
    "    requiredSelemWidth.append(requiredSelemWidthTmp)\n",
    "    # Dilate the mask\n",
    "    selem = ball(1) # radius of 5 mm\n",
    "    dilated = dilation(segmented_lungs_fill, selem) # dilate a bit according to the tut\n",
    "    # Apply the mask\n",
    "    pix_resampled_to_use = pix_resampled*dilated\n",
    "    # count the number of lung voxels to find those which are badly segmented\n",
    "    numVoxelsPerLungSeg.append(np.count_nonzero(dilated))\n",
    "    \n",
    "    print('Finding nodule masks')\n",
    "    # The mask\n",
    "    # put the mask on an array with the same shape as the original volume\n",
    "    one_segmentation_consensus = np.zeros_like(curr_patient_pixels)\n",
    "    one_segmentation_maxvol = np.zeros_like(curr_patient_pixels)\n",
    "    labelledNods = np.zeros_like(curr_patient_pixels)\n",
    "\n",
    "    # get all the annotations for this scan\n",
    "    ids = [i.id for i in scan.annotations] # this gives the annotation IDs (note that they are not in order in the annotations.csv)\n",
    "     \n",
    "    # we split the df for patient pid into the part for just this scan\n",
    "    df_patient_partX = df_patient.loc[df_patient.annotation_id.isin(ids)]\n",
    "    unique_nodules = np.unique(df_patient_partX['cluster_id'].values)\n",
    "    nods = scan.cluster_annotations() # get the annotations for all nodules in this scan\n",
    "\n",
    "    for unique_nodule in unique_nodules:\n",
    "        df_nodule = df_patient_partX.loc[df_patient_partX['cluster_id']==unique_nodule] # this gives all annotations for this nodule (cluster)\n",
    "     \n",
    "        anns = nods[unique_nodule] # then choose the annotation for the nodule we are considering\n",
    "    \n",
    "        try:\n",
    "            # cmask = consensus mask, cbbox = consensus bounding box, masks = original annotations\n",
    "            cmask,cbbox,masks = consensus(anns, clevel=0.5, pad=[(0,0), (0,0), (0,0)])\n",
    "        except NameError:\n",
    "            scans_with_errors.append(pid)\n",
    "            continue\n",
    "     \n",
    "        # we want to save the consensus AND the mask of all segmented voxels in all annotations\n",
    "        one_mask_consensus = cmask\n",
    "        one_mask_maxvol = np.zeros_like(cmask)\n",
    "        for mask in masks:\n",
    "            one_mask_maxvol = (one_mask_maxvol > 0) | (mask > 0)    \n",
    "        \n",
    "        # pylidc loads in a different order to our custom 3D dicom reader, so need to swap dims\n",
    "        one_mask_consensus = np.swapaxes(one_mask_consensus,1,2);one_mask_consensus = np.swapaxes(one_mask_consensus,0,1)\n",
    "        one_mask_maxvol = np.swapaxes(one_mask_maxvol,1,2);one_mask_maxvol = np.swapaxes(one_mask_maxvol,0,1)\n",
    "        \n",
    "        # Dilate the mask\n",
    "        one_mask_maxvol = dilation(one_mask_maxvol)\n",
    "        \n",
    "        # fill the consensus bounding box with the mask to get a nodule segmentation in original image space (presumably the cbbox is big enough for all the individual masks)\n",
    "        one_segmentation_consensus[cbbox[2].start:cbbox[2].stop,cbbox[0].start:cbbox[0].stop,cbbox[1].start:cbbox[1].stop] = one_mask_consensus\n",
    "        one_segmentation_maxvol[cbbox[2].start:cbbox[2].stop,cbbox[0].start:cbbox[0].stop,cbbox[1].start:cbbox[1].stop] = one_mask_maxvol\n",
    "        labelledNods[cbbox[2].start:cbbox[2].stop,cbbox[0].start:cbbox[0].stop,cbbox[1].start:cbbox[1].stop] = one_mask_maxvol * (unique_nodule + 1) # label each nodule with its 'cluster_id'\n",
    "\n",
    "    pass \n",
    "\n",
    "    labelledNods = labelledNods - 1 # to get background = - 1, and each nodule to contain its cluster id\n",
    "\n",
    "    # Resample the nodule segmentation\n",
    "    mask_consensus_resampled, _ = resample_grid_except_slices(one_segmentation_consensus, spacing_orig, [1,1,1],'nearest') # first patient still has the voxel size of the original image to enable the resampling\n",
    "    mask_maxvol_resampled, _ = resample_grid_except_slices(one_segmentation_maxvol, spacing_orig, [1,1,1],'nearest') # first patient still has the voxel size of the original image to enable the resampling\n",
    "    labelledNods_resampled, _ = resample_grid_except_slices(labelledNods, spacing_orig, [1,1,1],'nearest') # first patient still has the voxel size of the original image to enable the resampling\n",
    "\n",
    "    print('Saving...')\n",
    "    # now we save the results, saving each slice as a sparse array to cut down on size!\n",
    "    # (currently just saving the last nodule per scan?)\n",
    "    if not os.path.exists(f'{path_dest}{k}/scans'): os.makedirs(f'{path_dest}{k}/scans')\n",
    "    if not os.path.exists(f'{path_dest}{k}/consensus_masks'): os.makedirs(f'{path_dest}{k}/consensus_masks')\n",
    "    if not os.path.exists(f'{path_dest}{k}/maxvol_masks'): os.makedirs(f'{path_dest}{k}/maxvol_masks')\n",
    "    if not os.path.exists(f'{path_dest}{k}/lung_masks'): os.makedirs(f'{path_dest}{k}/lung_masks')\n",
    "    if not os.path.exists(f'{path_dest}{k}/cluster_id_images'): os.makedirs(f'{path_dest}{k}/cluster_id_images')\n",
    "\n",
    "\n",
    "    for idj,(slice_pix, slice_mask_consensus, slice_mask_maxvol,slice_lungseg, slice_cluster_id_image) in enumerate(zip(pix_resampled_to_use, mask_consensus_resampled, mask_maxvol_resampled,dilated,labelledNods_resampled)):\n",
    "        sparse_matrix = scipy.sparse.csc_matrix(slice_pix)\n",
    "        sparse_matrix2 = scipy.sparse.csc_matrix(slice_mask_consensus)\n",
    "        sparse_matrix3 = scipy.sparse.csc_matrix(slice_mask_maxvol)\n",
    "        sparse_matrix4 = scipy.sparse.csc_matrix(slice_lungseg)\n",
    "        sparse_matrix5 = scipy.sparse.csc_matrix(slice_cluster_id_image)\n",
    "\n",
    "        scipy.sparse.save_npz(f'{path_dest}{k}/scans/slice_{idj:04d}.npz', sparse_matrix, compressed=True)\n",
    "        scipy.sparse.save_npz(f'{path_dest}{k}/consensus_masks/slice_m_{idj:04d}.npz', sparse_matrix2, compressed=True)\n",
    "        scipy.sparse.save_npz(f'{path_dest}{k}/maxvol_masks/slice_m_{idj:04d}.npz', sparse_matrix3, compressed=True)\n",
    "        scipy.sparse.save_npz(f'{path_dest}{k}/lung_masks/slice_m_{idj:04d}.npz', sparse_matrix4, compressed=True)\n",
    "        scipy.sparse.save_npz(f'{path_dest}{k}/cluster_id_images/slice_m_{idj:04d}.npz', sparse_matrix5, compressed=True)\n",
    "\n",
    "#%% save some summary output\n",
    "np.savetxt(path_dest + 'segmentation_results.dat', numVoxelsPerLungSeg)\n",
    "\n",
    "np.savetxt(rejectListFile,listOfRejectedPatients,'%10s')\n",
    "rejectListFile.close()\n",
    "\n",
    "np.savetxt(useListFile,listOfUsedPatients,'%10s')\n",
    "useListFile.close()\n",
    "\n",
    "np.savetxt(selemZWidthFile,requiredSelemWidth,'%u')\n",
    "selemZWidthFile.close()\n",
    "\n",
    "np.savetxt(errorScansFile,scans_with_errors,'%10s')\n",
    "errorScansFile.close()\n",
    "\n",
    "#%% plot segmentation results\n",
    "# ax = plt.hist(numVoxelsPerLungSeg,100)\n",
    "# plt.xlabel('Number of voxels in segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_n = 90\n",
    "print(f'original shape {np.shape(curr_patient_pixels), spacing}')\n",
    "print(f'resampled shape {np.shape(pix_resampled)}')\n",
    "print(np.shape(pix_resampled_to_use),np.shape(mask_maxvol_resampled))\n",
    "fig, ax = plt.subplots(1,3, figsize=(14,5))\n",
    "ax[0].imshow(curr_patient_pixels[slice_n])\n",
    "ax[1].imshow(pix_resampled_to_use[slice_n])\n",
    "ax[2].imshow(mask_maxvol_resampled[slice_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make3d_from_sparse(path):\n",
    "    slices_all = os.listdir(path)\n",
    "    slices_all = np.sort(slices_all)\n",
    "    for idx, i in enumerate(slices_all):\n",
    "        sparse_matrix = sparse.load_npz(f'{path}{i}')\n",
    "        array2d = np.asarray(sparse_matrix.todense())\n",
    "        if idx == 0: \n",
    "            scan3d = array2d\n",
    "            continue\n",
    "        scan3d = np.dstack([scan3d,array2d])\n",
    "    return scan3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'LIDC-IDRI-0001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{path_data}{name}/scans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_slices3D_v2(path_data, ii_ids):\n",
    "    \"\"\"Read VOLUMES of lung, mask outside lungs and nodule, mask nodule, mask outside\"\"\"\n",
    "    #ii_ids = f'LIDC-IDRI-{idnumber:04d}'\n",
    "    print(f'reading scan {ii_ids}')\n",
    "    vol = make3d_from_sparse(f'{path_data}{ii_ids}/scans/')\n",
    "    mask = make3d_from_sparse(f'{path_data}{ii_ids}/consensus_masks/')\n",
    "    mask_maxvol = make3d_from_sparse(f'{path_data}{ii_ids}/maxvol_masks/')\n",
    "    mask_lungs = make3d_from_sparse(f'{path_data}{ii_ids}/lung_masks/')  \n",
    "    # rearrange axes to slices first\n",
    "    vol = np.swapaxes(vol,1,2)\n",
    "    vol = np.swapaxes(vol,0,1)\n",
    "    mask = np.swapaxes(mask,1,2)\n",
    "    mask = np.swapaxes(mask,0,1)\n",
    "    mask_maxvol = np.swapaxes(mask_maxvol,1,2)\n",
    "    mask_maxvol = np.swapaxes(mask_maxvol,0,1)\n",
    "    mask_lungs = np.swapaxes(mask_lungs,1,2)\n",
    "    mask_lungs = np.swapaxes(mask_lungs,0,1)\n",
    "    # Find the minimum box that contain the lungs \n",
    "    min_box = np.where(vol!=0)\n",
    "    min_box_c = min_box[0]\n",
    "    min_box_x = min_box[1]\n",
    "    min_box_y = min_box[2]\n",
    "    # Apply the minimum box to the vol and masks\n",
    "    vol_small = vol[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "    mask_small = mask[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "    mask_maxvol_small = mask_maxvol[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "    mask_lungs_small = mask_lungs[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)] \n",
    "    # Get the mask_maxvol_small and the mask_lungs_small together\n",
    "    mask_maxvol_and_lungs = 1- ((1-mask_lungs_small) | mask_maxvol_small)\n",
    "    mask_lungs_small2 = mask_lungs_small | mask_maxvol_small\n",
    "    return vol_small, mask_maxvol_small, mask_maxvol_and_lungs, mask_lungs_small2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_small, mask_maxvol_small, mask_maxvol_and_lungs_small, mask_lungs_small = read_slices3D_v2(path_dest, 'LIDC-IDRI-0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 59+12\n",
    "fig, ax = plt.subplots(1,4,figsize=(14,4))\n",
    "ax[0].imshow(vol_small[ii])\n",
    "ax[1].imshow(mask_maxvol_small[ii])\n",
    "ax[2].imshow(mask_maxvol_and_lungs_small[ii])\n",
    "ax[3].imshow(mask_lungs_small[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 59+12\n",
    "fig, ax = plt.subplots(1,4,figsize=(14,4))\n",
    "ax[0].imshow(vol_small[ii])\n",
    "ax[1].imshow(mask_maxvol_small[ii])\n",
    "ax[2].imshow(mask_maxvol_and_lungs_small[ii])\n",
    "ax[3].imshow(mask_lungs_small[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(np.arange(1,10)):\n",
    "    name = f'LIDC-IDRI-{i:04d}'\n",
    "    print(name)\n",
    "    vol_small, mask_maxvol_small, mask_maxvol_and_lungs, mask_lungs_small = read_slices3D(name)\n",
    "    z,x,y = np.where(mask_maxvol_small==1)\n",
    "    z_median = np.median(z)\n",
    "    slice_n = int(z_median)\n",
    "    fig, ax = plt.subplots(1,4, figsize=(14,5))\n",
    "    ax[0].imshow(vol_small[slice_n], vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask_maxvol_small[slice_n])\n",
    "    ax[2].imshow(mask_maxvol_and_lungs[slice_n])\n",
    "    ax[3].imshow(mask_lungs_small[slice_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'LIDC-IDRI-0001'\n",
    "lungs = make3d_from_sparse(f'{path_dest}{i}/scans/')\n",
    "mask = make3d_from_sparse(f'{path_dest}{i}/maxvol_masks/')\n",
    "mask_lungs = make3d_from_sparse(f'{path_dest}{i}/lung_masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange axes to slices first\n",
    "vol = lungs\n",
    "vol = np.swapaxes(vol,1,2)\n",
    "vol = np.swapaxes(vol,0,1)\n",
    "mask = np.swapaxes(mask,1,2)\n",
    "mask = np.swapaxes(mask,0,1)\n",
    "mask_lungs = np.swapaxes(mask_lungs,1,2)\n",
    "mask_lungs = np.swapaxes(mask_lungs,0,1)\n",
    "# Find the minimum box that contain the lungs \n",
    "min_box = np.where(vol!=0)\n",
    "min_box_c = min_box[0]\n",
    "min_box_x = min_box[1]\n",
    "min_box_y = min_box[2]\n",
    "vol_small = vol[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "# Apply the same minimum box to the mask\n",
    "mask_small = mask[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "mask_lungs_small = mask_lungs[np.min(min_box_c):np.max(min_box_c),np.min(min_box_x):np.max(min_box_x),np.min(min_box_y):np.max(min_box_y)]\n",
    "lungs = vol_small\n",
    "mask = mask_small\n",
    "mask_lungs = mask_lungs_small\n",
    "np.shape(lungs), np.shape(mask), np.shape(mask_lungs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_n=70\n",
    "fig, ax = plt.subplots(1,3, figsize=(14,5))\n",
    "ax[0].imshow(lungs[slice_n])\n",
    "ax[1].imshow(mask[slice_n])\n",
    "ax[2].imshow(mask_lungs_small[slice_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
